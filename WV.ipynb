{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L97pTnoUICZJ"
      },
      "source": [
        "!pip install memory_profiler\n",
        "!pip install line_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-t1CABeG3Wu"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from scipy.sparse import csr_matrix, csc_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bicn-zMjJIo0"
      },
      "source": [
        "%load_ext memory_profiler\n",
        "%load_ext line_profiler\n",
        "f1 = \"/content/drive/MyDrive/enwiki8.txt\"\n",
        "f2 = \"/content/drive/MyDrive/wordsim353_human_scores.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI1rJMNAWiHP"
      },
      "source": [
        "def parseUniqueWordsWcount(filename):\n",
        "  uniword = {}\n",
        "  with open(filename, \"r\") as file1:\n",
        "    text = file1.read()\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "      if word not in uniword:\n",
        "        uniword[word] = 1\n",
        "      else:\n",
        "        uniword[word] += 1\n",
        "    return uniword"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQTmDeQQ1Zr"
      },
      "source": [
        "def parseUniqueWords(filename):\n",
        "  with open(filename, \"r\") as file2:\n",
        "    lines = file2.read()\n",
        "    words = lines.split()\n",
        "    addwords = []\n",
        "    for word in words:\n",
        "      if \".\" not in word and word not in addwords:\n",
        "        addwords.append(word)\n",
        "  return addwords"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1JUPdYnYGtV"
      },
      "source": [
        "def genSparseData(filename, uniqword):\n",
        "  with open(filename, \"r\") as file1:\n",
        "    doculines = file1.readlines() \n",
        "  wordset = set(uniqword)\n",
        "  rows = []\n",
        "  cols = []\n",
        "  vals = []\n",
        "  for i in range(len(doculines)):\n",
        "    words = doculines[i].split()\n",
        "    tempfreq = [0] * len(uniqword) \n",
        "    for word in words:\n",
        "      if word in wordset:\n",
        "        tempfreq[uniqword.index(word)] += 1\n",
        "    # Progress check since this takes the longest parsing through the file\n",
        "    if i % 50000 == 0:\n",
        "      print(i)\n",
        "    # Basic Sparse data\n",
        "    for j in range(len(tempfreq)):\n",
        "      if tempfreq[j] > 0:\n",
        "        rows.append(j)\n",
        "        cols.append(i)\n",
        "        vals.append(tempfreq[j])\n",
        "  # conversion to csr sparse matrix format\n",
        "  datmat = csr_matrix((vals,(rows, cols)), dtype=float)\n",
        "  return datmat"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJgG0D1_sc_o"
      },
      "source": [
        "def libSVD(spmat ,kval):\n",
        "  u,sd,v = svds(spmat, k=kval)\n",
        "  return u, sd, v"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPkYwQ81Dspq"
      },
      "source": [
        "def matrix_factor(x, displacement, kval):\n",
        "  v = np.random.rand(kval, x.shape[1])\n",
        "  idmat = np.identity(kval)\n",
        "  u = np.zeros(())\n",
        "  max_iter = 50\n",
        "  for i in range(max_iter):\n",
        "    u = np.linalg.inv(v @ v.T + (displacement * idmat)) @ (v @ x.T)\n",
        "    v = np.linalg.inv(u @ u.T + (displacement * idmat)) @ (u @ x)\n",
        "    # iteration progress check \n",
        "    if i % 10 == 0:\n",
        "      print(i)\n",
        "  eval, evec = eigs(x @ x.T, k=kval)\n",
        "  evalmat = np.diag(eval)\n",
        "  return u, evalmat ,v"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1RCzrMJe2Ct"
      },
      "source": [
        "def correlationScores(filename, testerr, allwords):\n",
        "  humanscores = []\n",
        "  coscore = []\n",
        "  with open(filename, \"r\") as file2:\n",
        "    humanlines = file2.readlines()\n",
        "    for line in humanlines:\n",
        "      word = line.split()\n",
        "      #first word\n",
        "      fword = testerr[allwords.index(word[0])]\n",
        "      fword = (fword.reshape(fword.shape[0],1)).T\n",
        "      #second word\n",
        "      sword = testerr[allwords.index(word[1])]\n",
        "      sword = sword.reshape(sword.shape[0],1)\n",
        "      distance = (fword @ sword) / (np.linalg.norm(fword) * np.linalg.norm(sword))\n",
        "      humanscores.append(float(word[2]))\n",
        "      coscore.append(distance[0][0].real)\n",
        "  humanscores = np.array(humanscores)\n",
        "  coscore = np.array(coscore)\n",
        "  return humanscores, coscore"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AvV0SH7Xke7"
      },
      "source": [
        "def PCC(x, y):\n",
        "  stdx = np.std(x)\n",
        "  stdy = np.std(y)\n",
        "  score = (np.cov(x,y))[0][1] / (stdx * stdy)\n",
        "  return score"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04Q1aQx303A7"
      },
      "source": [
        "def PPMI(smat):\n",
        "  # All sums\n",
        "  total = float(smat.sum())\n",
        "  sumr = np.array(smat.sum(axis=1), dtype=np.float64).flatten()\n",
        "  sumc = np.array(smat.sum(axis=0), dtype=np.float64).flatten()\n",
        "  # used values\n",
        "  ii, jj = smat.nonzero()\n",
        "  fij = np.array(smat[ii,jj], dtype=np.float64).flatten()\n",
        "  # ppmi value\n",
        "  tempzri = sumr[ii]\n",
        "  tempzrj = sumc[jj]\n",
        "  pmi = np.log(fij * total / (sumr[ii] * sumc[jj]))\n",
        "  ppmi = np.maximum(0, pmi)\n",
        "  # reshape to original matrix\n",
        "  newmat = csr_matrix((ppmi, (ii,jj)), shape=smat.shape, dtype=np.float64)\n",
        "  # purge 0s\n",
        "  newmat.eliminate_zeros() \n",
        "  return newmat"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afmCyUM6Wmyr"
      },
      "source": [
        "uniword = parseUniqueWordsWcount(f1)\n",
        "toptk = sorted(uniword, key=uniword.get,reverse=True)[:10000]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXMA8bQnYPtD"
      },
      "source": [
        "extrawords = parseUniqueWords(f2)\n",
        "allwords = toptk.copy()\n",
        "for word in extrawords:\n",
        "  if word not in allwords:\n",
        "    allwords.append(word)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJEcOtB0rQlQ"
      },
      "source": [
        "smatrix = genSparseData(f1, allwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXjeTA1lAky9"
      },
      "source": [
        "# convert to csc since more columns than rows\n",
        "tempmat = smatrix.tocsc()\n",
        "jmatrix = PPMI(tempmat)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBov9BohNuwP"
      },
      "source": [
        "# change this for original matrix(jmatrix) vs pmi matrix(smatrix)\n",
        "usemat = smatrix\n",
        "k = 20\n",
        "%time %memit lu20, le20, lv20 = libSVD(usemat,k)\n",
        "%time %memit su20, se20, sv20 = matrix_factor(usemat, 0.1, k)\n",
        "k = 50\n",
        "%time %memit lu50, le50, lv50 = libSVD(usemat,k)\n",
        "%time %memit su50, se50, sv50 = matrix_factor(usemat, 0.1, k) \n",
        "k = 100\n",
        "%time %memit lu100, le100, lv100 = libSVD(usemat,k)\n",
        "%time %memit su100, se100, sv100 = matrix_factor(usemat, 0.1, k)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYq3pL_MX3FK"
      },
      "source": [
        "wordvec = su100.T @ se100\n",
        "humanscores, coscores = correlationScores(f2, wordvec, allwords)\n",
        "tester = PCC(humanscores, coscores)\n",
        "print(tester)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUl-Oj5cDtwL"
      },
      "source": [
        "humanscores,coscores = correlationScores(f2, lu100 @ np.diag(le100), allwords)\n",
        "tester = PCC(humanscores, coscores)\n",
        "print(tester)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTf2WKQeTwm"
      },
      "source": [
        "tsne = TSNE(n_components=2, random_state=0, method=\"exact\")\n",
        "o = usemat[:300]\n",
        "tsne_results = tsne.fit_transform(o)\n",
        "tsne_results = tsne_results.T"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCXvF-DAkcJW"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "ax.scatter(tsne_results[0], tsne_results[1])\n",
        "for i, txt in enumerate(allwords[:300]):\n",
        "    ax.annotate(txt, (tsne_results[0][i], tsne_results[1][i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}